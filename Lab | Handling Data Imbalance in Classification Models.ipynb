{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd425a1",
   "metadata": {},
   "source": [
    "![logo_ironhack_blue 7](https://user-images.githubusercontent.com/23629340/40541063-a07a0a8a-601a-11e8-91b5-2f13e4e6b441.png)\n",
    "\n",
    "# Lab | Handling Data Imbalance in Classification Models\n",
    "\n",
    "For this lab and in the next lessons we will use the dataset 'Healthcare For All' building a model to predict who will donate (TargetB) and how much they will give (TargetD) (will be used for lab on Friday). You will be using `files_for_lab/learningSet.csv` file which you have already downloaded from class.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are revisiting the Healthcare for All Case Study. You are provided with this historical data about Donors and how much they donated. Your task is to build a machine learning model that will help the company identify people who are more likely to donate and then try to predict the donation amount.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "In this lab, we will first take a look at the degree of imbalance in the data and correct it using the techniques we learned in the class.\n",
    "\n",
    "Here is the list of steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "- Import the required libraries and modules that you would need.\n",
    "- Read that data into Python and call the dataframe `donors`.\n",
    "- Check the datatypes of all the columns in the data. \n",
    "- Check for null values in the dataframe. Replace the null values using the methods learned in class.\n",
    "- Split the data into numerical and catagorical.  Decide if any columns need their dtype changed.\n",
    "- Concatenate numerical and categorical back together again for your X dataframe.  Designate the Target as y.\n",
    "  \n",
    "  - Split the data into a training set and a test set.\n",
    "  - Split further into train_num and train_cat.  Also test_num and test_cat.\n",
    "  - Scale the features either by using normalizer or a standard scaler. (train_num, test_num)\n",
    "  - Encode the categorical features using One-Hot Encoding or Ordinal Encoding.  (train_cat, test_cat)\n",
    "      - **fit** only on train data transform both train and test\n",
    "      - again re-concatenate train_num and train_cat as X_train as well as test_num and test_cat as X_test\n",
    "  - Fit a logistic regression model on the training data.\n",
    "  - Check the accuracy on the test data.\n",
    "\n",
    "**Note**: So far we have not balanced the data.\n",
    "\n",
    "Managing imbalance in the dataset\n",
    "\n",
    "- Check for the imbalance.\n",
    "- Use the resampling strategies used in class for upsampling and downsampling to create a balance between the two classes.\n",
    "- Each time fit the model and see how the accuracy of the model has changed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359ac9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd0d6197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        60.0\n",
       "1        46.0\n",
       "2         NaN\n",
       "3        70.0\n",
       "4        78.0\n",
       "         ... \n",
       "95407     NaN\n",
       "95408    48.0\n",
       "95409    60.0\n",
       "95410    58.0\n",
       "95411    80.0\n",
       "Name: AGE, Length: 95412, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors = pd.read_csv('learningSet.csv')\n",
    "donors['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb3f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODATEDW       int64\n",
       "OSOURCE      object\n",
       "TCODE         int64\n",
       "STATE        object\n",
       "ZIP          object\n",
       "             ...   \n",
       "MDMAUD_R     object\n",
       "MDMAUD_F     object\n",
       "MDMAUD_A     object\n",
       "CLUSTER2    float64\n",
       "GEOCODE2     object\n",
       "Length: 481, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d9c8c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE         23665\n",
       "NUMCHLD     83026\n",
       "INCOME      21286\n",
       "WEALTH1     44732\n",
       "MBCRAFT     52854\n",
       "            ...  \n",
       "RAMNT_24    77674\n",
       "NEXTDATE     9973\n",
       "TIMELAG      9973\n",
       "CLUSTER2      132\n",
       "GEOCODE2      132\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = donors.isna().sum()\n",
    "null_values = null_values[null_values > 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7ac6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = numerical_cols.fillna(numerical_cols.mean())\n",
    "categorical_cols = donors.select_dtypes(include=['object'])\n",
    "numerical_cols.fillna(method='ffill', inplace=True)\n",
    "categorical_cols.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b815a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([numerical_cols, categorical_cols], axis=1)\n",
    "y = donors['TARGET_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38b7e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f533770",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = X_train.select_dtypes(include=['float64', 'int64']).astype(str)\n",
    "train_cat = X_train.select_dtypes(include=['object']).astype(str)\n",
    "test_num = X_test.select_dtypes(include=['float64', 'int64']).astype(str)\n",
    "test_cat = X_test.select_dtypes(include=['object']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66998713",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_num_scaled = scaler.fit_transform(train_num)\n",
    "test_num_scaled = scaler.transform(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c219694",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "train_cat_encoded = encoder.fit_transform(train_cat)\n",
    "test_cat_encoded = encoder.transform(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f71c9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = pd.concat([pd.DataFrame(train_num_scaled), pd.DataFrame(train_cat_encoded.toarray())], axis=1)\n",
    "X_test_encoded = pd.concat([pd.DataFrame(test_num_scaled), pd.DataFrame(test_cat_encoded.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2d06e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "916bc502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999475973379448\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_encoded)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521019a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760cad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resampled = LogisticRegression()\n",
    "model_resampled.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_resampled = model_resampled.predict(X_test_encoded)\n",
    "accuracy_resampled = accuracy_score(y_test, y_pred_resampled)\n",
    "print(\"Accuracy (Upsampled):\", accuracy_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b162eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler()\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e310b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resampled = LogisticRegression()\n",
    "model_resampled.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea2b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8107061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e785f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
